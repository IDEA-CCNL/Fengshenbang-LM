{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkvUPtwnbzPt/m3EBgr2Nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bc67497a2ff4400b4cb5d88079fc4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38c63dcb92744829a9eaf03e4f2892e9",
              "IPY_MODEL_941b045debd84bf7bab088a8ff4e7bc1",
              "IPY_MODEL_0e900579b1d147d0a413fae1e4cf7cc6"
            ],
            "layout": "IPY_MODEL_63c819e001cd47f5935131119ba6ef5d"
          }
        },
        "38c63dcb92744829a9eaf03e4f2892e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090b427d0b274fdf93c95593f4ef95d9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_76d8b66fce1546c1a3230adee26fcf7b",
            "value": "Epoch 0:  17%"
          }
        },
        "941b045debd84bf7bab088a8ff4e7bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9aba368b5d4f5fa29c6323a3e2a4e7",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f3de25874ff4323b1071fdad388dc9e",
            "value": 1
          }
        },
        "0e900579b1d147d0a413fae1e4cf7cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf6d49d6d29e4871bcf60b072279abc6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e6f6150c24a244009b10d23865b6d375",
            "value": " 1/6 [00:09&lt;00:45,  9.06s/it, loss=0.0309, v_num=1, train_loss=0.0309]"
          }
        },
        "63c819e001cd47f5935131119ba6ef5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "090b427d0b274fdf93c95593f4ef95d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d8b66fce1546c1a3230adee26fcf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e9aba368b5d4f5fa29c6323a3e2a4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3de25874ff4323b1071fdad388dc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf6d49d6d29e4871bcf60b072279abc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f6150c24a244009b10d23865b6d375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanng-ide/Fengshenbang-colab/blob/main/finetune_taiyi_stable_diffusion_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñåÔ∏è **Finetuning Taiyi-Stable-Diffusion Colab Example**\n",
        "\n",
        "#####based on https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\n"
      ],
      "metadata": {
        "id": "-GisYq7cG41a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing fengshen framework"
      ],
      "metadata": {
        "id": "twrdGg5zaY0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "!pip install transformers\n",
        "!pip install deepspeed\n",
        "!pip install diffusers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "\n",
        "!git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y24PHP7dG4gj",
        "outputId": "e8af6343-4d50-4312-dcef-b251ff8584aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ÂàáÊç¢Â∑•‰ΩúË∑ØÂæÑ\n",
        "os.chdir('/content/Fengshenbang-LM')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwZ2CAgkLgda",
        "outputId": "2063f330-0289-4a55-f0d0-fa181c8414f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Fengshenbang-LM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building modules"
      ],
      "metadata": {
        "id": "EMYaGij5acpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CnXybs4VFJnz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "from pytorch_lightning import (\n",
        "    LightningModule,\n",
        "    Trainer,\n",
        ")\n",
        "from pytorch_lightning.callbacks import (\n",
        "    LearningRateMonitor,\n",
        ")\n",
        "from fengshen.data.universal_datamodule import UniversalDataModule\n",
        "from fengshen.models.model_utils import (\n",
        "    add_module_args,\n",
        "    configure_optimizers,\n",
        "    get_total_steps,\n",
        ")\n",
        "from fengshen.utils.universal_checkpoint import UniversalCheckpoint\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from diffusers import AutoencoderKL, DDPMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from torch.nn import functional as F\n",
        "from fengshen.data.taiyi_stable_diffusion_datasets.taiyi_datasets import add_data_args, load_data\n",
        "\n",
        "\n",
        "class StableDiffusion(LightningModule):\n",
        "    @staticmethod\n",
        "    def add_module_specific_args(parent_parser):\n",
        "        parser = parent_parser.add_argument_group('Taiyi Stable Diffusion Module')\n",
        "        parser.add_argument('--train_whole_model', action='store_true', default=False)\n",
        "        return parent_parser\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\n",
        "            args.model_path, subfolder=\"tokenizer\")\n",
        "        self.text_encoder = BertModel.from_pretrained(\n",
        "            args.model_path, subfolder=\"text_encoder\")  # load from taiyi_finetune-v0\n",
        "        self.vae = AutoencoderKL.from_pretrained(\n",
        "            args.model_path, subfolder=\"vae\")\n",
        "        self.unet = UNet2DConditionModel.from_pretrained(\n",
        "            args.model_path, subfolder=\"unet\")\n",
        "\n",
        "        self.noise_scheduler = DDPMScheduler(\n",
        "            beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000\n",
        "        )\n",
        "        self.save_hyperparameters(args)\n",
        "\n",
        "    def setup(self, stage) -> None:\n",
        "        if stage == 'fit':\n",
        "            self.total_steps = get_total_steps(self.trainer, self.hparams)\n",
        "            print('Total steps: {}' .format(self.total_steps))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        model_params = [{'params': self.text_encoder.parameters()}]\n",
        "        if self.hparams.train_whole_model:\n",
        "            model_params.append({'params': self.unet.parameters()})\n",
        "        return configure_optimizers(self, model_params=model_params)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.text_encoder.train()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            latents = self.vae.encode(batch[\"pixel_values\"]).latent_dist.sample()\n",
        "            latents = latents * 0.18215\n",
        "\n",
        "        # Sample noise that we'll add to the latents\n",
        "        noise = torch.randn(latents.shape).to(latents.device)\n",
        "        noise = noise.to(dtype=self.unet.dtype)\n",
        "        bsz = latents.shape[0]\n",
        "        # Sample a random timestep for each image\n",
        "        timesteps = torch.randint(\n",
        "            0, self.noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
        "        timesteps = timesteps.long()\n",
        "        # Add noise to the latents according to the noise magnitude at each timestep\n",
        "        # (this is the forward diffusion process)\n",
        "\n",
        "        noisy_latents = self.noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "        noisy_latents = noisy_latents.to(dtype=self.unet.dtype)\n",
        "\n",
        "        # Get the text embedding for conditioning\n",
        "        # with torch.no_grad():\n",
        "        encoder_hidden_states = self.text_encoder(batch[\"input_ids\"])[0]\n",
        "\n",
        "        # Predict the noise residual\n",
        "        noise_pred = self.unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "        loss = F.mse_loss(noise_pred, noise, reduction=\"none\").mean([1, 2, 3]).mean()\n",
        "        self.log(\"train_loss\", loss.item(),  on_epoch=False, prog_bar=True, logger=True)\n",
        "\n",
        "        if self.trainer.global_rank == 0 and self.global_step == 100:\n",
        "            # ÊâìÂç∞ÊòæÂ≠òÂç†Áî®\n",
        "            from fengshen.utils.utils import report_memory\n",
        "            report_memory('stable diffusion')\n",
        "\n",
        "        if self.trainer.global_rank == 0:\n",
        "            if (self.global_step+1) % 5000 == 0:\n",
        "                print('saving model...')\n",
        "                pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                    args.model_path, text_encoder=self.text_encoder, tokenizer=self.tokenizer,\n",
        "                )\n",
        "                self.trainer.current_epoch\n",
        "                pipeline.save_pretrained(os.path.join(\n",
        "                    args.default_root_dir, f'hf_out_{self.trainer.current_epoch}'))\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if self.trainer.global_rank == 0:\n",
        "            print('saving model...')\n",
        "            pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                args.model_path, text_encoder=self.text_encoder, tokenizer=self.tokenizer,\n",
        "            )\n",
        "            self.trainer.current_epoch\n",
        "            pipeline.save_pretrained(os.path.join(\n",
        "                args.default_root_dir, f'hf_out_{self.trainer.current_epoch}'))\n",
        "\n",
        "    def on_load_checkpoint(self, checkpoint) -> None:\n",
        "        # ÂÖºÂÆπ‰ΩéÁâàÊú¨lightningÔºå‰ΩéÁâàÊú¨lightning‰ªéckptËµ∑Êù•Êó∂stepsÊï∞‰ºöË¢´ÈáçÁΩÆ‰∏∫0\n",
        "        global_step_offset = checkpoint[\"global_step\"]\n",
        "        if 'global_samples' in checkpoint:\n",
        "            self.consumed_samples = checkpoint['global_samples']\n",
        "        self.trainer.fit_loop.epoch_loop._batches_that_stepped = global_step_offset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ],
      "metadata": {
        "id": "jN-ATKxi1TUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "args_parser = argparse.ArgumentParser()\n",
        "args_parser = add_module_args(args_parser)\n",
        "args_parser = add_data_args(args_parser)\n",
        "args_parser = UniversalDataModule.add_data_specific_args(args_parser)\n",
        "args_parser = Trainer.add_argparse_args(args_parser)\n",
        "args_parser = StableDiffusion.add_module_specific_args(args_parser)\n",
        "args_parser = UniversalCheckpoint.add_argparse_args(args_parser)\n",
        "\n",
        "# ‰Ω†ÁöÑÊï∞ÊçÆÈõÜÔºåÂèØ‰ª•ÂèÇËÄÉ https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/finetune_taiyi_stable_diffusion ÁöÑdemo_datasetÁöÑËÆæÁΩÆ\n",
        "your_dataset_path = '/content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset' #@param {type:\"string\"}\n",
        "# ÈªòËÆ§‰∏∫‰∏ãËΩΩhuggingface‰∏äÁöÑÊ®°Âûã\n",
        "your_model_path =  'IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1' #@param {type:\"string\"}\n",
        "train_batch_size = '1' #@param {type:\"string\"}\n",
        "\n",
        "message = [\n",
        "    '--datasets_path', your_dataset_path,\n",
        "    '--datasets_type', 'txt',\n",
        "    '--model_path', your_model_path,\n",
        "    '--train_batchsize', train_batch_size,\n",
        "    '--accelerator', 'gpu',\n",
        "    # '--strategy', 'deepspeed',\n",
        "    '--precision', '16'\n",
        "]\n",
        "\n",
        "args = args_parser.parse_args(args=message)\n",
        "\n",
        "pprint(vars(args), width = 230)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFnQFiQ_1S8w",
        "outputId": "5fc9a222-c475-4325-f506-ecb479554f89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accelerator': 'gpu',\n",
            " 'accumulate_grad_batches': None,\n",
            " 'adam_beta1': 0.9,\n",
            " 'adam_beta2': 0.999,\n",
            " 'adam_epsilon': 1e-08,\n",
            " 'amp_backend': 'native',\n",
            " 'amp_level': None,\n",
            " 'auto_lr_find': False,\n",
            " 'auto_scale_batch_size': False,\n",
            " 'auto_select_gpus': False,\n",
            " 'benchmark': None,\n",
            " 'center_crop': False,\n",
            " 'check_val_every_n_epoch': 1,\n",
            " 'dataloader_workers': 2,\n",
            " 'datasets_name': None,\n",
            " 'datasets_path': ['/content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset'],\n",
            " 'datasets_type': ['txt'],\n",
            " 'default_root_dir': None,\n",
            " 'detect_anomaly': False,\n",
            " 'deterministic': None,\n",
            " 'devices': None,\n",
            " 'enable_checkpointing': True,\n",
            " 'enable_model_summary': True,\n",
            " 'enable_progress_bar': True,\n",
            " 'every_n_epochs': None,\n",
            " 'every_n_train_steps': None,\n",
            " 'fast_dev_run': False,\n",
            " 'filename': 'model-{epoch:02d}-{train_loss:.4f}',\n",
            " 'gpus': None,\n",
            " 'gradient_clip_algorithm': None,\n",
            " 'gradient_clip_val': None,\n",
            " 'inference_mode': True,\n",
            " 'ipus': None,\n",
            " 'learning_rate': 5e-05,\n",
            " 'limit_predict_batches': None,\n",
            " 'limit_test_batches': None,\n",
            " 'limit_train_batches': None,\n",
            " 'limit_val_batches': None,\n",
            " 'load_ckpt_path': './ckpt/',\n",
            " 'log_every_n_steps': 50,\n",
            " 'logger': True,\n",
            " 'lr_decay_ratio': 1.0,\n",
            " 'lr_decay_steps': 0,\n",
            " 'max_epochs': None,\n",
            " 'max_steps': -1,\n",
            " 'max_time': None,\n",
            " 'min_epochs': None,\n",
            " 'min_learning_rate': 1e-07,\n",
            " 'min_steps': None,\n",
            " 'mode': 'min',\n",
            " 'model_path': 'IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1',\n",
            " 'monitor': 'train_loss',\n",
            " 'move_metrics_to_cpu': False,\n",
            " 'multiple_trainloader_mode': 'max_size_cycle',\n",
            " 'num_nodes': 1,\n",
            " 'num_processes': None,\n",
            " 'num_sanity_val_steps': 2,\n",
            " 'num_workers': 8,\n",
            " 'overfit_batches': 0.0,\n",
            " 'plugins': None,\n",
            " 'precision': 16,\n",
            " 'profiler': None,\n",
            " 'raw_file_type': 'json',\n",
            " 'reload_dataloaders_every_n_epochs': 0,\n",
            " 'replace_sampler_ddp': True,\n",
            " 'resolution': 512,\n",
            " 'resume_from_checkpoint': None,\n",
            " 'sampler_type': 'random',\n",
            " 'save_ckpt_path': './ckpt/',\n",
            " 'save_last': False,\n",
            " 'save_on_train_epoch_end': None,\n",
            " 'save_top_k': 3,\n",
            " 'save_weights_only': False,\n",
            " 'scheduler_type': 'polynomial',\n",
            " 'strategy': None,\n",
            " 'sync_batchnorm': False,\n",
            " 'test_batchsize': 16,\n",
            " 'test_datasets_field': 'test',\n",
            " 'test_file': None,\n",
            " 'thres': 0.2,\n",
            " 'tpu_cores': None,\n",
            " 'track_grad_norm': -1,\n",
            " 'train_batchsize': 1,\n",
            " 'train_datasets_field': 'train',\n",
            " 'train_file': None,\n",
            " 'train_whole_model': False,\n",
            " 'val_batchsize': 16,\n",
            " 'val_check_interval': None,\n",
            " 'val_datasets_field': 'validation',\n",
            " 'val_file': None,\n",
            " 'warmup_ratio': 0.1,\n",
            " 'warmup_steps': 0,\n",
            " 'weight_decay': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start training"
      ],
      "metadata": {
        "id": "sgSAEhHoagek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yALlfBnj4AUF",
        "outputId": "4bca183d-21bf-4d46-8de3-538ec8f8b67f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 26 08:44:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "MemTotal:       13297228 kB\n",
            "MemFree:         9999676 kB\n",
            "MemAvailable:   11723668 kB\n",
            "Buffers:          194128 kB\n",
            "Cached:          1644720 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           468260 kB\n",
            "Inactive:        2546228 kB\n",
            "Active(anon):      11932 kB\n",
            "Inactive(anon):  1084696 kB\n",
            "Active(file):     456328 kB\n",
            "Inactive(file):  1461532 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               376 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       1175772 kB\n",
            "Mapped:           530300 kB\n",
            "Shmem:              1176 kB\n",
            "KReclaimable:      95168 kB\n",
            "Slab:             133072 kB\n",
            "SReclaimable:      95168 kB\n",
            "SUnreclaim:        37904 kB\n",
            "KernelStack:        4320 kB\n",
            "PageTables:        20916 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648612 kB\n",
            "Committed_AS:    3012680 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       52800 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1352 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      340800 kB\n",
            "DirectMap2M:    11190272 kB\n",
            "DirectMap1G:     4194304 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1vid40pLVDF",
        "outputId": "dd487068-39c6-4934-f3c1-6c8feb09b075"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.3.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = StableDiffusion(args)\n",
        "tokenizer = model.tokenizer\n",
        "datasets = load_data(args, tokenizer=tokenizer)\n",
        "\n",
        "def collate_fn(examples):\n",
        "    # print(examples)\n",
        "    input_ids = [example[\"instance_prompt_ids\"] for example in examples]\n",
        "    pixel_values = [example[\"instance_images\"] for example in examples]\n",
        "\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "    input_ids = tokenizer.pad({\"input_ids\": input_ids}, padding=True,\n",
        "                                return_tensors=\"pt\").input_ids\n",
        "    batch = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"pixel_values\": pixel_values,\n",
        "    }\n",
        "\n",
        "    return batch\n",
        "\n",
        "datamoule = UniversalDataModule(\n",
        "    tokenizer=tokenizer, collate_fn=collate_fn, args=args, datasets=datasets)\n",
        "\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "checkpoint_callback = UniversalCheckpoint(args)\n",
        "\n",
        "trainer = Trainer.from_argparse_args(args,\n",
        "                                        callbacks=[\n",
        "                                            lr_monitor,\n",
        "                                            checkpoint_callback])\n",
        "\n",
        "trainer.fit(model, datamoule, ckpt_path=args.load_ckpt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601,
          "referenced_widgets": [
            "0bc67497a2ff4400b4cb5d88079fc4bf",
            "38c63dcb92744829a9eaf03e4f2892e9",
            "941b045debd84bf7bab088a8ff4e7bc1",
            "0e900579b1d147d0a413fae1e4cf7cc6",
            "63c819e001cd47f5935131119ba6ef5d",
            "090b427d0b274fdf93c95593f4ef95d9",
            "76d8b66fce1546c1a3230adee26fcf7b",
            "8e9aba368b5d4f5fa29c6323a3e2a4e7",
            "9f3de25874ff4323b1071fdad388dc9e",
            "cf6d49d6d29e4871bcf60b072279abc6",
            "e6f6150c24a244009b10d23865b6d375"
          ]
        },
        "id": "b4nSmmNrLVwG",
        "outputId": "8c750abe-fd9d-42c1-aadc-5c1cf0f34be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading folder data from /content/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/demo_dataset/part_0.\n",
            "Done loading data. Len of images: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------warning no checkpoint found--------, remove args\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:97: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  category=PossibleUserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total steps: 6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name         | Type                 | Params\n",
            "------------------------------------------------------\n",
            "0 | text_encoder | BertModel            | 102 M \n",
            "1 | vae          | AutoencoderKL        | 83.7 M\n",
            "2 | unet         | UNet2DConditionModel | 859 M \n",
            "------------------------------------------------------\n",
            "1.0 B     Trainable params\n",
            "0         Non-trainable params\n",
            "1.0 B     Total params\n",
            "2,090.885 Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1562: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bc67497a2ff4400b4cb5d88079fc4bf"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}